{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Architectures:\n",
    "- VGG16 ( https://arxiv.org/pdf/1409.1556.pdf )\n",
    "- ResNet34\n",
    "    - Skip connections\n",
    "    - Global Average Pooling\n",
    "- Making activations gaussian: Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 (https://arxiv.org/pdf/1409.1556.pdf), gained prominence around 2014. This architecture and associated weights are open sourced and can be accessed very easily. The schematics of the network can be found here ( https://neurohive.io/en/popular-networks/vgg16/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def O(I,K,P,S):\n",
    "    return ((I-K+2*P)/(S))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Input 224,224,3\n",
    "#### Source : https://github.com/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-vgg16.ipynb\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        self.block1=nn.Sequential(nn.Conv2d(in_channels=3,\n",
    "                                            out_channels=64,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(in_channels=64,\n",
    "                                            out_channels=64,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                             stride=(2, 2))) \n",
    "        self.block2=nn.Sequential(nn.Conv2d(in_channels=64,\n",
    "                                            out_channels=128,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(in_channels=128,\n",
    "                                            out_channels=128,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                             stride=(2, 2)))\n",
    "        self.block3=nn.Sequential(nn.Conv2d(in_channels=128,\n",
    "                                            out_channels=256,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(in_channels=256,\n",
    "                                            out_channels=256,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_channels=256,\n",
    "                                            out_channels=256,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                             stride=(2, 2)))\n",
    "        self.block4=nn.Sequential(nn.Conv2d(in_channels=256,\n",
    "                                            out_channels=512,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(in_channels=512,\n",
    "                                            out_channels=512,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_channels=512,\n",
    "                                            out_channels=512,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                             stride=(2, 2)))\n",
    "        self.block5=nn.Sequential(nn.Conv2d(in_channels=512,\n",
    "                                            out_channels=512,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Conv2d(in_channels=512,\n",
    "                                            out_channels=512,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_channels=512,\n",
    "                                            out_channels=512,\n",
    "                                           kernel_size=(3,3),\n",
    "                                           padding=1,\n",
    "                                           stride=1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                             stride=(2, 2)))\n",
    "        self.classifier=nn.Sequential(nn.Linear(in_features=512*7*7,out_features=4096),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(in_features=4096,out_features=4096),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(4096,num_classes)\n",
    "    def forward(self,X):\n",
    "            x = self.block1(X)\n",
    "            x = self.block2(x)\n",
    "            x = self.block3(x)\n",
    "            x = self.block4(x)\n",
    "            x = self.block5(x)\n",
    "            x=x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "            x=self.classifier(x)\n",
    "            x=nn.functional.softmax(x,dim=1)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=VGG16(h=224,w=224,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet\n",
    "- Residual networks use skip connections so that very deep networks can be trained (https://arxiv.org/pdf/1512.03385.pdf)\n",
    "- The key idea is that of \"residual learning\".\n",
    "- Build a very simple skip-connection implimentation\n",
    "\n",
    "<img src=\"residual.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###input 1*28*28\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,\n",
    "                            out_channels=4,\n",
    "                            kernel_size=(1,1),\n",
    "                            stride=1,\n",
    "                            padding=0)\n",
    "        self.bn=nn.BatchNorm2d(num_features=4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        shortcut=x\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        x+=shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=torch.randn(2,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impliment a Residual block such that:**\n",
    "- The input is $1*28*28$\n",
    "- A conv layer reduces the size to $8*14*14$\n",
    "- The skip connection has to be resized before merging\n",
    "\n",
    "<img src=\"ex.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
