{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCN are used in semantic segmentation tasks. We will write FCN32, FCN16 and FCN8. \n",
    "Original paper \n",
    "\n",
    "(https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf) \n",
    "\n",
    "and implimentation \n",
    "\n",
    "(https://github.com/zijundeng/pytorch-semantic-segmentation/blob/master/models/fcn32s.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 512, 7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(512,4096,kernel_size=7).weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 4096, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(4096,4096,kernel_size=1).weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN32(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        model=models.vgg16(pretrained=True)\n",
    "        features=model.features\n",
    "        classifier=model.classifier\n",
    "        features[0].padding=(100,100) #(https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/pascalcontext-fcn32s/net.py)\n",
    "        self.features5=features\n",
    "        fc6=nn.Conv2d(512,4096,kernel_size=7)\n",
    "        fc6.weight.data.copy_(classifier[0].weight.data.view(4096,512,7,7))\n",
    "        fc6.bias.data.copy_(classifier[0].bias.data)\n",
    "        fc7=nn.Conv2d(4096,4096,kernel_size=1)\n",
    "        fc7.weight.data.copy_(classifier[3].weight.data.view(4096,4096,1,1))\n",
    "        fc7.bias.data.copy_(classifier[3].bias.data)\n",
    "        scores=nn.Conv2d(4096,num_classes,kernel_size=1)\n",
    "        self.scores=nn.Sequential(fc6,nn.ReLU(inplace=True),nn.Dropout(),\n",
    "                                  fc7,nn.ReLU(inplace=True),nn.Dropout(),\n",
    "                                 scores) #(1,2,7,7)\n",
    "        self.upsample=nn.ConvTranspose2d(num_classes,num_classes,kernel_size=64,stride=32,bias=False)\n",
    "    def forward(self,X):\n",
    "        X_size = X.size()\n",
    "        X=self.features5(X)\n",
    "        X=self.scores(X)\n",
    "        X=self.upsample(X)\n",
    "        X=torch.sigmoid(X)\n",
    "        #return X[:, :, 19: (19 + X_size[2]), 19: (19 + X_size[3])].contiguous() ### Original paper Crop() [https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/pascalcontext-fcn32s/net.py]\n",
    "        #return X[:,:,0:X_size[2],0:X_size[3]]\n",
    "        return X[:,:,16:16+X_size[2],16:16+X_size[3]] ### Center Crop ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=FCN32(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=torch.randn(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (3): ReLU(inplace=True)\n",
       "   (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (6): ReLU(inplace=True)\n",
       "   (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (8): ReLU(inplace=True)\n",
       "   (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (11): ReLU(inplace=True)\n",
       "   (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (13): ReLU(inplace=True)\n",
       "   (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (15): ReLU(inplace=True)\n",
       "   (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (18): ReLU(inplace=True)\n",
       "   (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (20): ReLU(inplace=True)\n",
       "   (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (22): ReLU(inplace=True)\n",
       "   (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (25): ReLU(inplace=True)\n",
       "   (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (27): ReLU(inplace=True)\n",
       "   (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (29): ReLU(inplace=True)\n",
       "   (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ), Sequential(\n",
       "   (0): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Dropout(p=0.5, inplace=False)\n",
       "   (3): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "   (4): ReLU(inplace=True)\n",
       "   (5): Dropout(p=0.5, inplace=False)\n",
       "   (6): Conv2d(4096, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       " )]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in m.children()][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*[i for i in m.children()][0:-1])(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[i for i in FCN32(2).children()][0:2]\\nm=nn.Sequential(*[i for i in FCN32(2).children()][0:2])\\nm(sample).shape\\nvgg16=models.vgg16(pretrained=True)\\nm_t=vgg16.features\\nm_t(sample).shape'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''[i for i in FCN32(2).children()][0:2]\n",
    "m=nn.Sequential(*[i for i in FCN32(2).children()][0:2])\n",
    "m(sample).shape\n",
    "vgg16=models.vgg16(pretrained=True)\n",
    "m_t=vgg16.features\n",
    "m_t(sample).shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.features[0:24]#### This is pool4 output, this then passes through a 1*1 convolution\n",
    "### then through upsampling: stride 1 padding 0, producing output of 26*26, this is then upsampled with kernel size 4, stride 2, resulting\n",
    "### in size of 30*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FCN16 #########\n",
    "class FCN16(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        mod=models.vgg16(pretrained=True)\n",
    "        features=mod.features\n",
    "        classifier=mod.classifier\n",
    "        features[0].padding=(100,100)\n",
    "        self.features4 = nn.Sequential(*features[: 24])\n",
    "        self.features5 = nn.Sequential(*features[24:])\n",
    "\n",
    "        self.score_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.score_pool4.weight.data.zero_()\n",
    "        self.score_pool4.bias.data.zero_()\n",
    "\n",
    "        fc6 = nn.Conv2d(512, 4096, kernel_size=7)\n",
    "        fc6.weight.data.copy_(classifier[0].weight.data.view(4096, 512, 7, 7))\n",
    "        fc6.bias.data.copy_(classifier[0].bias.data)\n",
    "        fc7 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
    "        fc7.weight.data.copy_(classifier[3].weight.data.view(4096, 4096, 1, 1))\n",
    "        fc7.bias.data.copy_(classifier[3].bias.data)\n",
    "        score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "        score_fr.weight.data.zero_()\n",
    "        score_fr.bias.data.zero_()\n",
    "        self.score_fr = nn.Sequential(\n",
    "            fc6, nn.ReLU(inplace=True), nn.Dropout(), fc7, nn.ReLU(inplace=True), nn.Dropout(), score_fr\n",
    "        )\n",
    "\n",
    "        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, bias=False)\n",
    "        self.upscore16 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=32, stride=16, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        pool4 = self.features4(x)\n",
    "        #print(f'pool4 {pool4.shape}')\n",
    "        pool5 = self.features5(pool4)\n",
    "\n",
    "        score_fr = self.score_fr(pool5)\n",
    "        upscore2 = self.upscore2(score_fr) ##16*16\n",
    "\n",
    "        score_pool4 = self.score_pool4(0.01 * pool4) ### 26*26\n",
    "        #print(f\"score_pool4:{score_pool4.shape}, upsocore2:{upscore2.shape}\")\n",
    "        upscore16 = self.upscore16(score_pool4[:, :, 5: (5 + upscore2.size()[2]), 5: (5 + upscore2.size()[3])]\n",
    "                                   + upscore2)\n",
    "        #print(f\"upscore16:{upscore16.shape}\") ## 272*272 (272-224)/2\n",
    "        return upscore16[:, :, 24: (24 + x_size[2]), 24: (24 + x_size[3])].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn16=FCN16(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcn16(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN8(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        mod=models.vgg16(pretrained=True)\n",
    "        features=mod.features\n",
    "        classifier=mod.classifier\n",
    "        features[0].padding=(100,100)\n",
    "        self.features3 = nn.Sequential(*features[: 17])\n",
    "        self.features4 = nn.Sequential(*features[17: 24])\n",
    "        self.features5 = nn.Sequential(*features[24:])\n",
    "\n",
    "        self.score_pool3 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        self.score_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.score_pool3.weight.data.zero_()\n",
    "        self.score_pool3.bias.data.zero_()\n",
    "        self.score_pool4.weight.data.zero_()\n",
    "        self.score_pool4.bias.data.zero_()\n",
    "\n",
    "        fc6 = nn.Conv2d(512, 4096, kernel_size=7)\n",
    "        fc6.weight.data.copy_(classifier[0].weight.data.view(4096, 512, 7, 7))\n",
    "        fc6.bias.data.copy_(classifier[0].bias.data)\n",
    "        fc7 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
    "        fc7.weight.data.copy_(classifier[3].weight.data.view(4096, 4096, 1, 1))\n",
    "        fc7.bias.data.copy_(classifier[3].bias.data)\n",
    "        score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "        score_fr.weight.data.zero_()\n",
    "        score_fr.bias.data.zero_()\n",
    "        self.score_fr = nn.Sequential(\n",
    "            fc6, nn.ReLU(inplace=True), nn.Dropout(), fc7, nn.ReLU(inplace=True), nn.Dropout(), score_fr\n",
    "        )\n",
    "\n",
    "        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, bias=False)\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, bias=False)\n",
    "        self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=16, stride=8, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        pool3 = self.features3(x)\n",
    "        pool4 = self.features4(pool3)\n",
    "        pool5 = self.features5(pool4)\n",
    "        #print(f\"pool3: {pool3.shape}, pool4: {pool4.shape}, pool5: {pool5.shape}\")\n",
    "        score_fr = self.score_fr(pool5)\n",
    "        #print(f\"score_fr: {score_fr.shape}\")\n",
    "        upscore2 = self.upscore2(score_fr)\n",
    "        #print(f\"upscore2: {upscore2.shape}\")\n",
    "        score_pool4 = self.score_pool4(0.01 * pool4)\n",
    "        upscore_pool4 = self.upscore_pool4(score_pool4[:, :, 5: (5 + upscore2.size()[2]), 5: (5 + upscore2.size()[3])]\n",
    "                                           + upscore2)\n",
    "        #print(f\"upscore_pool4: {upscore_pool4.shape}\")\n",
    "        score_pool3 = self.score_pool3(0.0001 * pool3)\n",
    "        upscore8 = self.upscore8(score_pool3[:, :, 9: (9 + upscore_pool4.size()[2]), 9: (9 + upscore_pool4.size()[3])]\n",
    "                                 + upscore_pool4)\n",
    "        #print(f\"upscore8: {upscore8.shape}\")\n",
    "        return upscore8[:, :, 28: (28 + x_size[2]), 28: (28 + x_size[3])].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn8=FCN8(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 224, 224])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcn8(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
